{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tunning_1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMRUF0hXDfj3edGTk91HexY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leeje008/ML_final_project/blob/main/final_code/Tunning_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxG8f5YSe3kF",
        "outputId": "5c16bf22-ab2c-4ad0-d6fb-13dc0b168a44"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Rln1Roee6pK"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV \n",
        "from sklearn.metrics import  confusion_matrix,recall_score,precision_score,accuracy_score\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier  \n",
        "from xgboost import XGBClassifier\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_clf_eval(y_test,pred):\n",
        "    confusion = confusion_matrix(y_test, pred)\n",
        "    accuracy = accuracy_score(y_test, pred)\n",
        "    precision = precision_score(y_test, pred)\n",
        "    recall = recall_score(y_test, pred)\n",
        "    roc = roc_auc_score(y_test, pred)\n",
        "    g_mean = geometric_mean_score(y_test, pred)\n",
        "    print('오차행렬')\n",
        "    print(confusion)\n",
        "    print('정확도: {0:4f}, 정밀도 {1:4f}, 재현율 {2:4f}, AUC {3:4f},G_MEAN {4:4f}'.format(accuracy , precision , recall,roc,g_mean))\n",
        "    \n",
        "\n",
        "def get_model_train_eval(model,ftr_train = None, ftr_test = None, tgt_train = None, tgt_test = None):\n",
        "    model.fit(ftr_train, tgt_train)\n",
        "    pred = model.predict(ftr_test)\n",
        "    get_clf_eval(tgt_test, pred)\n",
        "\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTqQWYNVe6rp"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Loan_Train.csv')\n",
        "df.head()\n",
        "\n",
        "df = df.drop('Id',axis = 1)\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "labelEncoder = LabelEncoder()\n",
        "\n",
        "data = df\n",
        "\n",
        "\n",
        "for e in data.columns:\n",
        "    if data[e].dtype == 'object':\n",
        "        labelEncoder.fit(list(data[e].values))\n",
        "        data[e] = labelEncoder.transform(data[e].values)\n",
        "        \n",
        "        # Accommodate the data that has been changed\n",
        "        df = data\n",
        "        \n",
        "y = df.Risk_Flag\n",
        "X = df.drop('Risk_Flag', axis=1)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                                                   y,\n",
        "                                                   test_size=0.3,\n",
        "                                                   random_state=101)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiJJw0OQv6ma"
      },
      "source": [
        "# Hyperpameter tunning RF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaD5rdfvoIZh"
      },
      "source": [
        "! pip install smote-variants\n",
        "\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.over_sampling import SVMSMOTE\n",
        "from imblearn.over_sampling import ADASYN\n",
        "import smote_variants as sv\n",
        "from sklearn.metrics import roc_auc_score, make_scorer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XffgM1dde67Z"
      },
      "source": [
        "start = time.time()\n",
        "\n",
        "\n",
        "pipeline = Pipeline(steps= [(\"SMOTE\", SMOTE(random_state = 101)),\n",
        "                            (\"RandomForestClassifier\", RandomForestClassifier())\n",
        "                            ])\n",
        "\n",
        "param_grid = {\n",
        "    \"SMOTE__sampling_strategy\": [0.5,0.75,1],\n",
        "    \"RandomForestClassifier__n_estimators\": [100,200,300,400,500]\n",
        "              }\n",
        "\n",
        "\n",
        "\n",
        "gs_pipeline = GridSearchCV(pipeline, param_grid=param_grid, verbose=2, scoring=make_scorer(roc_auc_score), cv = 5)\n",
        "gs_pipeline.fit(X_train, y_train)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(f\"{end - start:.5f} sec\")\n",
        "\n",
        "# Store the best model\n",
        "smote_best_model = gs_pipeline.best_estimator_\n",
        "\n",
        "y_validation_preds = smote_best_model.predict(X_test)\n",
        "roc_auc_score(y_test, y_validation_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeeGql1i5lvR"
      },
      "source": [
        "## 결과물 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hizXq_C3e7Bq"
      },
      "source": [
        "scores_df = pd.DataFrame(gs_pipeline.cv_results_)\n",
        "scores_df.to_csv('/content/drive/MyDrive/RF_SMOTE.csv',index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcdjvRbsr1yP"
      },
      "source": [
        "# RF ADA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qlh9KMtue7Cu"
      },
      "source": [
        "start = time.time()\n",
        "\n",
        "\n",
        "pipeline = Pipeline(steps= [(\"ada\", ADASYN(random_state = 101)),\n",
        "                            (\"RandomForestClassifier\", RandomForestClassifier())\n",
        "                            ])\n",
        "\n",
        "param_grid = {\n",
        "    \"ada__sampling_strategy\": [0.5,0.75,1],\n",
        "    \"RandomForestClassifier__n_estimators\": [100,200,300,400,500]\n",
        "              }\n",
        "\n",
        "\n",
        "\n",
        "gs_pipeline_1 = GridSearchCV(pipeline, param_grid=param_grid, verbose=2, scoring=make_scorer(roc_auc_score), cv = 5)\n",
        "gs_pipeline_1.fit(X_train, y_train)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(f\"{end - start:.5f} sec\")\n",
        "\n",
        "# Store the best model\n",
        "\n",
        "\n",
        "scores_df = pd.DataFrame(gs_pipeline_1.cv_results_)\n",
        "scores_df.to_csv('/content/drive/MyDrive/RF_ADA.csv',index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBvULkJasOrl"
      },
      "source": [
        "# RF SVR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6HJ9PUmu-l8"
      },
      "source": [
        "start = time.time()\n",
        "\n",
        "\n",
        "pipeline = Pipeline(steps= [(\"SVR\", sv.distance_SMOTE()),\n",
        "                            (\"RF\", RandomForestClassifier())\n",
        "                            ])\n",
        "\n",
        "param_grid = {\n",
        "    \"SVR__proportion\": [0.5,0.75,1],\n",
        "    \"RF__n_estimators\": [100,200,300,400,500]\n",
        "              }\n",
        "\n",
        "\n",
        "\n",
        "gs_pipeline_1 = GridSearchCV(pipeline, param_grid=param_grid, verbose=2, scoring=make_scorer(roc_auc_score), cv = 5)\n",
        "gs_pipeline_1.fit(np.array(X_train), np.array(y_train))\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(f\"{end - start:.5f} sec\")\n",
        "\n",
        "# Store the best model\n",
        "\n",
        "\n",
        "scores_df = pd.DataFrame(gs_pipeline_1.cv_results_)\n",
        "scores_df.to_csv('/content/drive/MyDrive/RF_SVR.csv',index = False)\n",
        "\n",
        "svr_best_model = gs_pipeline_1.best_estimator_\n",
        "\n",
        "\n",
        "y_validation_preds = svr_best_model.predict(np.array(X_test))\n",
        "\n",
        "roc_auc_score(y_test, y_validation_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsLRIvv8sSyP"
      },
      "source": [
        "# LGB hyperparameter tunning\n",
        "# LGB SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npZlPPvjvFKt"
      },
      "source": [
        "start = time.time()\n",
        "\n",
        "\n",
        "pipeline = Pipeline(steps= [((\"SMOTE\",  SMOTE(random_state = 101))),\n",
        "                             (\"LGBClassifier\", LGBMClassifier(boost_from_average = False))\n",
        "                             ])\n",
        "\n",
        "param_grid = {\n",
        "    \"SMOTE__sampling_strategy\": [0.5,0.75,1],\n",
        "    \"LGBClassifier__n_estimators\": [100,200,300,400,500]\n",
        "              }\n",
        "\n",
        "\n",
        "\n",
        "gs_pipeline = GridSearchCV(pipeline, param_grid=param_grid, verbose=2, scoring=make_scorer(roc_auc_score), cv = 5)\n",
        "gs_pipeline.fit(X_train, y_train)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(f\"{end - start:.5f} sec\")\n",
        "\n",
        "\n",
        "\n",
        "scores_df = pd.DataFrame(gs_pipeline.cv_results_)\n",
        "scores_df.to_csv('/content/drive/MyDrive/LGB_SMOTE.csv',index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8RuFLgUzi7z"
      },
      "source": [
        "# LGB ADASYN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrE4Cq-BvIuZ"
      },
      "source": [
        "start = time.time()\n",
        "\n",
        "\n",
        "pipeline = Pipeline(steps= [((\"ada\",  ADASYN(random_state = 101))),\n",
        "                             (\"LGBClassifier\", LGBMClassifier(boost_from_average = False))\n",
        "                             ])\n",
        "\n",
        "param_grid = {\n",
        "    \"ada__sampling_strategy\": [0.5,0.75,1],\n",
        "    \"LGBClassifier__n_estimators\": [100,200,300,400,500]\n",
        "              }\n",
        "\n",
        "\n",
        "\n",
        "gs_pipeline = GridSearchCV(pipeline, param_grid=param_grid, verbose=2, scoring=make_scorer(roc_auc_score), cv = 5)\n",
        "gs_pipeline.fit(X_train, y_train)\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(f\"{end - start:.5f} sec\")\n",
        "\n",
        "\n",
        "\n",
        "scores_df = pd.DataFrame(gs_pipeline.cv_results_)\n",
        "scores_df.to_csv('/content/drive/MyDrive/LGB_ADASYN.csv',index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYee2eab4KVD"
      },
      "source": [
        "# LGB SVR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHGy_t0WoHI9"
      },
      "source": [
        "start = time.time()\n",
        "\n",
        "\n",
        "pipeline = Pipeline(steps= [(\"SVR\", sv.distance_SMOTE()),\n",
        "                            (\"LGB\", LGBMClassifier())\n",
        "                            ])\n",
        "\n",
        "param_grid = {\n",
        "    \"SVR__proportion\": [0.5,0.75,1],\n",
        "    \"LGB__n_estimators\": [100,200,300,400,500]\n",
        "              }\n",
        "\n",
        "\n",
        "\n",
        "gs_pipeline_1 = GridSearchCV(pipeline, param_grid=param_grid, verbose=2, scoring=make_scorer(roc_auc_score), cv = 5)\n",
        "gs_pipeline_1.fit(np.array(X_train), np.array(y_train))\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(f\"{end - start:.5f} sec\")\n",
        "\n",
        "# Store the best model\n",
        "\n",
        "\n",
        "scores_df = pd.DataFrame(gs_pipeline_1.cv_results_)\n",
        "scores_df.to_csv('/content/drive/MyDrive/LGB_SVR.csv',index = False)\n",
        "\n",
        "svr_best_model = gs_pipeline_1.best_estimator_\n",
        "\n",
        "\n",
        "y_validation_preds = svr_best_model.predict(np.array(X_test))\n",
        "\n",
        "roc_auc_score(y_test, y_validation_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byn9R3494i9X"
      },
      "source": [
        "# KNN SVR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYkk0iUkoRRY"
      },
      "source": [
        "start = time.time()\n",
        "\n",
        "\n",
        "pipeline = Pipeline(steps= [(\"SVR\", sv.distance_SMOTE()),\n",
        "                            (\"KNeighborsClassifier\", KNeighborsClassifier())\n",
        "                            ])\n",
        "\n",
        "param_grid = {\n",
        "    \"SVR__proportion\": [0.5,0.75,1],\n",
        "    \"KNeighborsClassifier__n_neighbors\": list(range(10,101,10))\n",
        "              }\n",
        "\n",
        "\n",
        "\n",
        "gs_pipeline_1 = GridSearchCV(pipeline, param_grid=param_grid, verbose=2, scoring=make_scorer(roc_auc_score), cv = 5)\n",
        "gs_pipeline_1.fit(np.array(X_train), np.array(y_train))\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(f\"{end - start:.5f} sec\")\n",
        "\n",
        "svr_best_model = gs_pipeline_1.best_estimator_\n",
        "\n",
        "\n",
        "y_validation_preds = svr_best_model.predict(np.array(X_test))\n",
        "\n",
        "roc_auc_score(y_test, y_validation_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnSRc2155POu"
      },
      "source": [
        "def plot_grid_search(cv_results, grid_param_1, grid_param_2, name_param_1, name_param_2):\n",
        "    # Get Test Scores Mean and std for each grid search\n",
        "    scores_mean = cv_results['mean_test_score']\n",
        "    scores_mean = np.array(scores_mean).reshape(len(grid_param_2),len(grid_param_1))\n",
        "\n",
        "    scores_sd = cv_results['std_test_score']\n",
        "    scores_sd = np.array(scores_sd).reshape(len(grid_param_2),len(grid_param_1))\n",
        "\n",
        "    # Plot Grid search scores\n",
        "    _, ax = plt.subplots(1,1)\n",
        "\n",
        "    # Param1 is the X-axis, Param 2 is represented as a different curve (color line)\n",
        "    for idx, val in enumerate(grid_param_2):\n",
        "        ax.plot(grid_param_1, scores_mean[idx,:], '-o', label= name_param_2 + ': ' + str(val))\n",
        "\n",
        "    ax.set_title(\"Grid Search Scores\", fontsize=20, fontweight='bold')\n",
        "    ax.set_xlabel(name_param_1, fontsize=16)\n",
        "    ax.set_ylabel('CV Average Score', fontsize=16)\n",
        "    ax.legend(loc=\"best\", fontsize=15)\n",
        "    ax.grid('on')\n",
        "\n",
        "# Calling Method \n",
        "plot_grid_search(pipe_grid.cv_results_, n_estimators, max_features, 'N Estimators', 'Max Features')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJGGpqVdn4O0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7NbxXFEn4VU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI90hk0Tn4bT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}